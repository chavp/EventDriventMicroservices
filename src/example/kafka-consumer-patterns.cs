using System;
using System.Collections.Concurrent;
using System.Threading;
using System.Threading.Channels;
using System.Threading.Tasks;
using Confluent.Kafka;
using Newtonsoft.Json;
using System.Collections.Generic;
using System.Linq;

// ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏™‡πà‡∏á
public class OrderMessage
{
    public string OrderId { get; set; }
    public string ProductName { get; set; }
    public int Quantity { get; set; }
    public decimal Price { get; set; }
    public DateTime OrderDate { get; set; }
}

public class MessageWithMetadata
{
    public ConsumeResult<string, string> ConsumeResult { get; set; }
    public OrderMessage Order { get; set; }
    public DateTime ReceivedAt { get; set; }
}

// ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡πà 1: Sequential Processing (‡πÅ‡∏ö‡∏ö‡πÄ‡∏î‡∏¥‡∏°)
public class SequentialKafkaConsumer
{
    private readonly IConsumer<string, string> _consumer;
    
    public SequentialKafkaConsumer(string bootstrapServers, string groupId)
    {
        var config = new ConsumerConfig
        {
            GroupId = groupId,
            BootstrapServers = bootstrapServers,
            AutoOffsetReset = AutoOffsetReset.Earliest,
            EnableAutoCommit = false
        };
        
        _consumer = new ConsumerBuilder<string, string>(config).Build();
    }
    
    public async Task StartConsumingAsync(string topic, CancellationToken cancellationToken)
    {
        _consumer.Subscribe(topic);
        Console.WriteLine("üîÑ Sequential Consumer Started");
        
        while (!cancellationToken.IsCancellationRequested)
        {
            var consumeResult = _consumer.Consume(cancellationToken);
            
            // Process ‡πÅ‡∏ö‡∏ö Sequential - ‡∏£‡∏≠‡πÉ‡∏´‡πâ‡∏à‡∏ö‡∏Å‡πà‡∏≠‡∏ô‡∏ñ‡∏∂‡∏á‡∏à‡∏∞‡πÑ‡∏õ consume ‡∏ï‡πà‡∏≠
            await ProcessMessageSequentialAsync(consumeResult);
            
            _consumer.Commit(consumeResult);
        }
    }
    
    private async Task ProcessMessageSequentialAsync(ConsumeResult<string, string> result)
    {
        var order = JsonConvert.DeserializeObject<OrderMessage>(result.Value);
        Console.WriteLine($"üì¶ [Sequential] Processing: {order.OrderId}");
        
        // ‡∏à‡∏≥‡∏•‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤‡∏ô‡∏≤‡∏ô
        await Task.Delay(3000);
        
        Console.WriteLine($"‚úÖ [Sequential] Completed: {order.OrderId}");
    }
}

// ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡πà 2: Fire-and-Forget Parallel Processing
public class FireAndForgetKafkaConsumer
{
    private readonly IConsumer<string, string> _consumer;
    
    public FireAndForgetKafkaConsumer(string bootstrapServers, string groupId)
    {
        var config = new ConsumerConfig
        {
            GroupId = groupId,
            BootstrapServers = bootstrapServers,
            AutoOffsetReset = AutoOffsetReset.Earliest,
            EnableAutoCommit = false
        };
        
        _consumer = new ConsumerBuilder<string, string>(config).Build();
    }
    
    public async Task StartConsumingAsync(string topic, CancellationToken cancellationToken)
    {
        _consumer.Subscribe(topic);
        Console.WriteLine("üöÄ Fire-and-Forget Consumer Started");
        
        while (!cancellationToken.IsCancellationRequested)
        {
            var consumeResult = _consumer.Consume(cancellationToken);
            
            // ‡∏™‡πà‡∏á‡πÑ‡∏õ process ‡πÅ‡∏ö‡∏ö parallel ‡∏ó‡∏±‡∏ô‡∏ó‡∏µ ‡πÑ‡∏°‡πà‡∏£‡∏≠‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
            _ = Task.Run(async () => await ProcessMessageAsync(consumeResult));
            
            // Commit ‡∏ó‡∏±‡∏ô‡∏ó‡∏µ (‡∏≠‡∏±‡∏ô‡∏ï‡∏£‡∏≤‡∏¢! ‡∏≠‡∏≤‡∏à‡∏ó‡∏≥‡πÉ‡∏´‡πâ message ‡∏´‡∏≤‡∏¢‡πÑ‡∏î‡πâ)
            _consumer.Commit(consumeResult);
        }
    }
    
    private async Task ProcessMessageAsync(ConsumeResult<string, string> result)
    {
        var order = JsonConvert.DeserializeObject<OrderMessage>(result.Value);
        Console.WriteLine($"üì¶ [Fire&Forget] Processing: {order.OrderId}");
        
        await Task.Delay(3000);
        
        Console.WriteLine($"‚úÖ [Fire&Forget] Completed: {order.OrderId}");
    }
}

// ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡πà 3: Producer-Consumer Pattern with Channel
public class ProducerConsumerKafkaProcessor
{
    private readonly IConsumer<string, string> _consumer;
    private readonly Channel<MessageWithMetadata> _processingQueue;
    private readonly int _maxParallelTasks;
    
    public ProducerConsumerKafkaProcessor(string bootstrapServers, string groupId, int maxParallelTasks = 5)
    {
        var config = new ConsumerConfig
        {
            GroupId = groupId,
            BootstrapServers = bootstrapServers,
            AutoOffsetReset = AutoOffsetReset.Earliest,
            EnableAutoCommit = false,
            MaxPollIntervalMs = 300000 // 5 ‡∏ô‡∏≤‡∏ó‡∏µ
        };
        
        _consumer = new ConsumerBuilder<string, string>(config).Build();
        _maxParallelTasks = maxParallelTasks;
        
        // ‡∏™‡∏£‡πâ‡∏≤‡∏á channel ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö queue ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        var options = new BoundedChannelOptions(100) // queue ‡πÑ‡∏î‡πâ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î 100 messages
        {
            FullMode = BoundedChannelFullMode.Wait,
            SingleReader = false,
            SingleWriter = true
        };
        _processingQueue = Channel.CreateBounded<MessageWithMetadata>(options);
    }
    
    public async Task StartConsumingAsync(string topic, CancellationToken cancellationToken)
    {
        _consumer.Subscribe(topic);
        Console.WriteLine($"‚ö° Producer-Consumer Started (Max Parallel: {_maxParallelTasks})");
        
        // ‡πÄ‡∏£‡∏¥‡πà‡∏° worker tasks ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö process ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        var processingTasks = Enumerable.Range(0, _maxParallelTasks)
            .Select(i => ProcessWorkerAsync(i, cancellationToken))
            .ToArray();
        
        // Consumer loop
        var consumerTask = Task.Run(async () =>
        {
            try
            {
                while (!cancellationToken.IsCancellationRequested)
                {
                    var consumeResult = _consumer.Consume(cancellationToken);
                    
                    var order = JsonConvert.DeserializeObject<OrderMessage>(consumeResult.Value);
                    var messageWithMetadata = new MessageWithMetadata
                    {
                        ConsumeResult = consumeResult,
                        Order = order,
                        ReceivedAt = DateTime.UtcNow
                    };
                    
                    // ‡∏™‡πà‡∏á‡πÄ‡∏Ç‡πâ‡∏≤ queue ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ worker process
                    await _processingQueue.Writer.WriteAsync(messageWithMetadata, cancellationToken);
                }
            }
            finally
            {
                _processingQueue.Writer.Complete();
            }
        });
        
        // ‡∏£‡∏≠‡πÉ‡∏´‡πâ‡∏ó‡∏∏‡∏Å task ‡πÄ‡∏™‡∏£‡πá‡∏à
        await Task.WhenAll(new[] { consumerTask }.Concat(processingTasks));
    }
    
    private async Task ProcessWorkerAsync(int workerId, CancellationToken cancellationToken)
    {
        Console.WriteLine($"üë∑ Worker {workerId} started");
        
        await foreach (var message in _processingQueue.Reader.ReadAllAsync(cancellationToken))
        {
            try
            {
                Console.WriteLine($"üì¶ [Worker-{workerId}] Processing: {message.Order.OrderId}");
                
                // ‡∏à‡∏≥‡∏•‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô
                await Task.Delay(3000, cancellationToken);
                
                Console.WriteLine($"‚úÖ [Worker-{workerId}] Completed: {message.Order.OrderId}");
                
                // Commit ‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å process ‡πÄ‡∏™‡∏£‡πá‡∏à
                _consumer.Commit(message.ConsumeResult);
            }
            catch (Exception ex)
            {
                Console.WriteLine($"‚ùå [Worker-{workerId}] Error processing {message.Order.OrderId}: {ex.Message}");
                // ‡πÉ‡∏ô‡∏Å‡∏£‡∏ì‡∏µ‡∏à‡∏£‡∏¥‡∏á ‡∏≠‡∏≤‡∏à‡∏ï‡πâ‡∏≠‡∏á‡∏™‡πà‡∏á‡πÑ‡∏õ dead letter queue
            }
        }
        
        Console.WriteLine($"üë∑ Worker {workerId} finished");
    }
}

// ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡πà 4: Batch Processing with Parallel Execution
public class BatchParallelKafkaConsumer
{
    private readonly IConsumer<string, string> _consumer;
    private readonly int _batchSize;
    private readonly int _maxParallelTasks;
    
    public BatchParallelKafkaConsumer(string bootstrapServers, string groupId, int batchSize = 10, int maxParallelTasks = 3)
    {
        var config = new ConsumerConfig
        {
            GroupId = groupId,
            BootstrapServers = bootstrapServers,
            AutoOffsetReset = AutoOffsetReset.Earliest,
            EnableAutoCommit = false
        };
        
        _consumer = new ConsumerBuilder<string, string>(config).Build();
        _batchSize = batchSize;
        _maxParallelTasks = maxParallelTasks;
    }
    
    public async Task StartConsumingAsync(string topic, CancellationToken cancellationToken)
    {
        _consumer.Subscribe(topic);
        Console.WriteLine($"üì¶ Batch Parallel Consumer Started (Batch: {_batchSize}, Parallel: {_maxParallelTasks})");
        
        var batch = new List<ConsumeResult<string, string>>();
        
        while (!cancellationToken.IsCancellationRequested)
        {
            var consumeResult = _consumer.Consume(TimeSpan.FromSeconds(1));
            if (consumeResult != null)
            {
                batch.Add(consumeResult);
            }
            
            // Process batch ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏Ñ‡∏£‡∏ö size ‡∏´‡∏£‡∏∑‡∏≠ timeout
            if (batch.Count >= _batchSize || (batch.Count > 0 && consumeResult == null))
            {
                await ProcessBatchAsync(batch.ToList());
                
                // Commit ‡∏ó‡∏±‡πâ‡∏á batch
                foreach (var result in batch)
                {
                    _consumer.Commit(result);
                }
                
                batch.Clear();
            }
        }
        
        // Process batch ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏•‡∏∑‡∏≠
        if (batch.Count > 0)
        {
            await ProcessBatchAsync(batch);
            foreach (var result in batch)
            {
                _consumer.Commit(result);
            }
        }
    }
    
    private async Task ProcessBatchAsync(List<ConsumeResult<string, string>> batch)
    {
        Console.WriteLine($"üîÑ Processing batch of {batch.Count} messages");
        
        // ‡πÅ‡∏ö‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô chunks ‡πÄ‡∏û‡∏∑‡πà‡∏≠ process parallel
        var chunks = batch
            .Select((item, index) => new { item, index })
            .GroupBy(x => x.index % _maxParallelTasks)
            .Select(g => g.Select(x => x.item).ToList())
            .ToList();
        
        var tasks = chunks.Select(async chunk =>
        {
            foreach (var result in chunk)
            {
                var order = JsonConvert.DeserializeObject<OrderMessage>(result.Value);
                Console.WriteLine($"üì¶ [Batch] Processing: {order.OrderId}");
                
                await Task.Delay(2000); // ‡∏à‡∏≥‡∏•‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô
                
                Console.WriteLine($"‚úÖ [Batch] Completed: {order.OrderId}");
            }
        });
        
        await Task.WhenAll(tasks);
        Console.WriteLine($"‚ú® Batch processing completed!");
    }
}

// ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡πà 5: Multi-Partition Parallel Consumer
public class MultiPartitionKafkaConsumer
{
    private readonly string _bootstrapServers;
    private readonly string _groupId;
    private readonly string _topic;
    
    public MultiPartitionKafkaConsumer(string bootstrapServers, string groupId, string topic)
    {
        _bootstrapServers = bootstrapServers;
        _groupId = groupId;
        _topic = topic;
    }
    
    public async Task StartMultipleConsumersAsync(int consumerCount, CancellationToken cancellationToken)
    {
        Console.WriteLine($"üöÄ Starting {consumerCount} parallel consumers");
        
        var tasks = Enumerable.Range(0, consumerCount)
            .Select(i => StartSingleConsumerAsync(i, cancellationToken))
            .ToArray();
        
        await Task.WhenAll(tasks);
    }
    
    private async Task StartSingleConsumerAsync(int consumerId, CancellationToken cancellationToken)
    {
        var config = new ConsumerConfig
        {
            GroupId = _groupId,
            BootstrapServers = _bootstrapServers,
            AutoOffsetReset = AutoOffsetReset.Earliest,
            EnableAutoCommit = false
        };
        
        using var consumer = new ConsumerBuilder<string, string>(config).Build();
        consumer.Subscribe(_topic);
        
        Console.WriteLine($"üë§ Consumer {consumerId} started");
        
        while (!cancellationToken.IsCancellationRequested)
        {
            try
            {
                var consumeResult = consumer.Consume(cancellationToken);
                
                var order = JsonConvert.DeserializeObject<OrderMessage>(consumeResult.Value);
                Console.WriteLine($"üì¶ [Consumer-{consumerId}] Processing: {order.OrderId} from partition {consumeResult.Partition}");
                
                await Task.Delay(2000, cancellationToken);
                
                Console.WriteLine($"‚úÖ [Consumer-{consumerId}] Completed: {order.OrderId}");
                
                consumer.Commit(consumeResult);
            }
            catch (OperationCanceledException)
            {
                break;
            }
            catch (Exception ex)
            {
                Console.WriteLine($"‚ùå [Consumer-{consumerId}] Error: {ex.Message}");
            }
        }
        
        Console.WriteLine($"üë§ Consumer {consumerId} stopped");
    }
}

// ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô
class Program
{
    private const string BOOTSTRAP_SERVERS = "localhost:9092";
    private const string TOPIC_NAME = "orders";
    private const string CONSUMER_GROUP = "parallel-processors";

    static async Task Main(string[] args)
    {
        Console.WriteLine("üöÄ Kafka Parallel Processing Examples");
        Console.WriteLine("Choose processing pattern:");
        Console.WriteLine("1. Sequential Processing (‡πÅ‡∏ö‡∏ö‡πÄ‡∏î‡∏¥‡∏°)");
        Console.WriteLine("2. Fire-and-Forget Parallel");
        Console.WriteLine("3. Producer-Consumer Pattern");
        Console.WriteLine("4. Batch Parallel Processing");
        Console.WriteLine("5. Multi-Partition Consumers");
        Console.WriteLine("6. Performance Comparison");
        
        var choice = Console.ReadLine();
        var cancellationTokenSource = new CancellationTokenSource();
        
        // Handle Ctrl+C
        Console.CancelKeyPress += (_, e) =>
        {
            e.Cancel = true;
            cancellationTokenSource.Cancel();
            Console.WriteLine("\nüõë Shutting down...");
        };
        
        try
        {
            switch (choice)
            {
                case "1":
                    await RunSequentialConsumer(cancellationTokenSource.Token);
                    break;
                case "2":
                    await RunFireAndForgetConsumer(cancellationTokenSource.Token);
                    break;
                case "3":
                    await RunProducerConsumerPattern(cancellationTokenSource.Token);
                    break;
                case "4":
                    await RunBatchParallelConsumer(cancellationTokenSource.Token);
                    break;
                case "5":
                    await RunMultiPartitionConsumers(cancellationTokenSource.Token);
                    break;
                case "6":
                    await RunPerformanceComparison(cancellationTokenSource.Token);
                    break;
                default:
                    Console.WriteLine("Invalid option!");
                    break;
            }
        }
        catch (OperationCanceledException)
        {
            Console.WriteLine("Operation cancelled by user.");
        }
    }
    
    static async Task RunSequentialConsumer(CancellationToken cancellationToken)
    {
        var consumer = new SequentialKafkaConsumer(BOOTSTRAP_SERVERS, CONSUMER_GROUP + "-sequential");
        await consumer.StartConsumingAsync(TOPIC_NAME, cancellationToken);
    }
    
    static async Task RunFireAndForgetConsumer(CancellationToken cancellationToken)
    {
        var consumer = new FireAndForgetKafkaConsumer(BOOTSTRAP_SERVERS, CONSUMER_GROUP + "-fireforget");
        await consumer.StartConsumingAsync(TOPIC_NAME, cancellationToken);
    }
    
    static async Task RunProducerConsumerPattern(CancellationToken cancellationToken)
    {
        var consumer = new ProducerConsumerKafkaProcessor(BOOTSTRAP_SERVERS, CONSUMER_GROUP + "-prodcons", 3);
        await consumer.StartConsumingAsync(TOPIC_NAME, cancellationToken);
    }
    
    static async Task RunBatchParallelConsumer(CancellationToken cancellationToken)
    {
        var consumer = new BatchParallelKafkaConsumer(BOOTSTRAP_SERVERS, CONSUMER_GROUP + "-batch", 5, 3);
        await consumer.StartConsumingAsync(TOPIC_NAME, cancellationToken);
    }
    
    static async Task RunMultiPartitionConsumers(CancellationToken cancellationToken)
    {
        var consumer = new MultiPartitionKafkaConsumer(BOOTSTRAP_SERVERS, CONSUMER_GROUP + "-multi", TOPIC_NAME);
        await consumer.StartMultipleConsumersAsync(3, cancellationToken); // 3 consumers
    }
    
    static async Task RunPerformanceComparison(CancellationToken cancellationToken)
    {
        Console.WriteLine("üìä Performance Comparison");
        Console.WriteLine("Running different patterns for 30 seconds each...\n");
        
        var patterns = new[]
        {
            ("Sequential", () => new SequentialKafkaConsumer(BOOTSTRAP_SERVERS, CONSUMER_GROUP + "-perf-seq")),
            ("Producer-Consumer", () => new ProducerConsumerKafkaProcessor(BOOTSTRAP_SERVERS, CONSUMER_GROUP + "-perf-pc", 3))
        };
        
        foreach (var (name, factory) in patterns)
        {
            Console.WriteLine($"üîÑ Testing {name} pattern...");
            var testCancellation = new CancellationTokenSource(TimeSpan.FromSeconds(30));
            
            try
            {
                if (factory() is SequentialKafkaConsumer seqConsumer)
                {
                    await seqConsumer.StartConsumingAsync(TOPIC_NAME, testCancellation.Token);
                }
                else if (factory() is ProducerConsumerKafkaProcessor pcConsumer)
                {
                    await pcConsumer.StartConsumingAsync(TOPIC_NAME, testCancellation.Token);
                }
            }
            catch (OperationCanceledException)
            {
                Console.WriteLine($"‚úÖ {name} test completed\n");
            }
        }
    }
}